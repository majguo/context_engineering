{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514e034b",
   "metadata": {},
   "source": [
    "# Writing Context in LangGraph\n",
    "\n",
    "*Writing context means saving it outside the context window to help an agent perform a task.*\n",
    "\n",
    "## Scratchpad\n",
    "\n",
    "When humans solve tasks, we take notes and remember things for future, related tasks. Agents are also gaining these capabilities! Note-taking via a \"[scratchpad](https://www.anthropic.com/engineering/claude-think-tool)\" is one approach to persist information while an agent is performing a task. The central idea is to save information outside of the context window so that it's available to the agent on-demand. [Anthropic's multi-agent researcher](https://www.anthropic.com/engineering/built-multi-agent-research-system) illustrates a clear example of this:\n",
    "\n",
    "> The LeadResearcher begins by thinking through the approach and saving its plan to Memory to persist the context, since if the context window exceeds 200,000 tokens it will be truncated and it is important to retain the plan.\n",
    "\n",
    "It's worth noting that this scratchpad can be implemented in a few different ways. It could be a [tool call](https://www.anthropic.com/engineering/claude-think-tool) that [writes to a file](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem). It could also just be a field in a runtime [state object](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) that persists during the session. In either case, the intuition is clear: scratchpads let agents save useful information during a session to help them accomplish tasks.\n",
    "\n",
    "### Scratchpad writing in LangGraph\n",
    "\n",
    "LangGraph was designed with first-class support of both thread-scoped ([short-term](https://langchain-ai.github.io/langgraph/concepts/memory/#short-term-memory)) and [long-term memory](https://langchain-ai.github.io/langgraph/concepts/memory/#long-term-memory). Short-term memory uses [checkpointing](https://langchain-ai.github.io/langgraph/concepts/persistence/) to persist [agent state](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) across all steps of an agent session. This is extremely useful as s \"scratchpad\", allowing you to write information to state during agent execution and fetch it later as needed.\n",
    "\n",
    "The state object in LangGraph serves as the central data structure that gets passed between nodes in your graph. It's a Python dictionary that can contain any JSON-serializable values including strings, numbers, lists, and dictionaries. The state acts as a shared workspace where each node can read from and write to specific fields. LangGraph uses TypedDict to provide type hints and structure to the state, making it clear what data is expected and maintained throughout the graph execution.\n",
    "\n",
    "Here we can create a state object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e9da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2993b0",
   "metadata": {},
   "source": [
    "Once we've defined a state object, how do write context to it using LangGraph?\n",
    "\n",
    "A StateGraph is LangGraph's core abstraction for building stateful, multi-step workflows. Think of it as a directed graph where each node represents a function that can read from and modify the shared state, and edges define the flow of execution between nodes. Nodes are the individual processing steps in your workflow - they receive the current state as input and return updates to be merged back into the state. Edges connect these nodes together, creating a path for execution that can be linear, conditional, or even cyclical depending on your needs.\n",
    "\n",
    "Let's create a [chat model](https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html) selecting from [Anthropic](https://docs.anthropic.com/en/docs/about-claude/models/overview) and use it with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab896d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"anthropic:claude-sonnet-4-20250514\", temperature=0)\n",
    "\n",
    "# Nodes\n",
    "def generate_joke(state: State):\n",
    "    \"\"\"First LLM call to generate initial joke\"\"\"\n",
    "    msg = llm.invoke(f\"Write a short joke about {state['topic']}\")\n",
    "    # Write the joke to state\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "# Build workflow\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"generate_joke\", generate_joke)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "workflow.add_edge(START, \"generate_joke\")\n",
    "workflow.add_edge(\"generate_joke\", END)\n",
    "\n",
    "# Compile\n",
    "chain = workflow.compile()\n",
    "\n",
    "# Show workflow\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777ddeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'cats',\n",
       " 'joke': \"Why don't cats ever win races?\\n\\nBecause they always paws right before the finish line!\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke\n",
    "joke_generator_state = chain.invoke({\"topic\": \"cats\"})\n",
    "\n",
    "# See joke is in state\n",
    "joke_generator_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4628949e",
   "metadata": {},
   "source": [
    "#### Learn More\n",
    " \n",
    "* `Checkpointing`: Checkpointing in LangGraph creates snapshots of your graph's state after each node execution, enabling powerful capabilities for long-running tasks. These checkpoints act as save points that allow you to pause execution, resume from any point, and even rewind to previous states. This is particularly valuable for complex workflows that might take hours or days to complete, as it provides fault tolerance and the ability to recover from failures without losing progress.\n",
    "\n",
    "* `Human-in-the-loop`: LangGraph's state persistence enables sophisticated human-in-the-loop workflows by allowing execution to be paused at any point and resumed later. This means you can interrupt a running graph, wait for human input or approval, and then continue processing from exactly where you left off. The checkpointed state ensures that all context and progress is preserved across these interruptions, making it possible to build workflows that seamlessly blend automated processing with human oversight and decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b90259f",
   "metadata": {},
   "source": [
    "## Memory \n",
    "\n",
    "Scratchpads helps agents solve a task within a given session, but sometimes agents benefit from remembering things across *many* sessions! [Reflexion](https://arxiv.org/abs/2303.11366) introduced the idea of reflection following each agent turn and re-using these self-generated hints. [Generative Agents](https://ar5iv.labs.arxiv.org/html/2304.03442) created memories synthesized periodically from collections of past agent feedback.\n",
    "\n",
    "These concepts made their way into popular products like [ChatGPT](https://help.openai.com/en/articles/8590148-memory-faq), [Cursor](https://forum.cursor.com/t/0-51-memories-feature/98509), and [Windsurf](https://docs.windsurf.com/windsurf/cascade/memories), which all have mechanisms to auto-generate long-term memories based on user-agent interactions.\n",
    "\n",
    "### Memory writing in LangGraph\n",
    "\n",
    "LangGraph’s long-term memory allows you to persist specific context *across many sessions* with your agent. It is flexible, allowing you to save [individual files](https://langchain-ai.github.io/langgraph/concepts/memory/#profile) (e.g., a user profile) or [collections](https://langchain-ai.github.io/langgraph/concepts/memory/#collection) of memories. In LangGraph, the `InMemoryStore` is just a Python dictionary in memory. LangGraph deployments [support long-term memory](https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/memory.ipynb) with persistence on the local filesystem (for local deployments) or PostgreSQL for hosted deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017c200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "store = InMemoryStore()\n",
    "\n",
    "# Define namespace (user_id, application_context)\n",
    "namespace = (\"rlm\", \"joke_generator\")\n",
    "\n",
    "# Write joke\n",
    "store.put(\n",
    "    namespace, # namespace\n",
    "    \"last_joke\", # key\n",
    "    {\"joke\": joke_generator_state[\"joke\"]} # value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49251dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "# Initialize storage and checkpointer\n",
    "checkpointer = InMemorySaver()\n",
    "memory_store = InMemoryStore()\n",
    "\n",
    "# Nodes\n",
    "def generate_joke(state: State, store: BaseStore):\n",
    "    \"\"\"First LLM call to generate initial joke\"\"\"\n",
    "\n",
    "    # Generate joke\n",
    "    msg = llm.invoke(f\"Write a short joke about {state['topic']}\")\n",
    "\n",
    "    # Write joke in memory\n",
    "    store.put(namespace, \"last_joke\", {\"joke\": msg.content})\n",
    "\n",
    "    # Write the joke to state\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "# Build workflow\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"generate_joke\", generate_joke)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "workflow.add_edge(START, \"generate_joke\")\n",
    "workflow.add_edge(\"generate_joke\", END)\n",
    "\n",
    "# Re-compile with checkpointing and memory  \n",
    "chain = workflow.compile(checkpointer=checkpointer, store=memory_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "449c7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "joke_generator_state = chain.invoke({\"topic\": \"cats\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "107d5cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior joke: Why don't cats ever win at poker?\n",
      "\n",
      "Because they can't help but purr when they have a good hand!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "joke_generator_state = chain.invoke({\"topic\": \"cats\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7be6b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't cats ever win races?\\n\\nBecause they always paws right before the finish line!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_generator_state['joke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb528512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why don't cats ever win races?\\n\\nBecause they always paws right before the finish line!\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that we wrote the memory\n",
    "memory_store.get(namespace, \"last_joke\").value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268b24b",
   "metadata": {},
   "source": [
    "#### Learn More\n",
    "\n",
    "* [LangMem](https://langchain-ai.github.io/langmem/) provides a set of useful abstractions to aid with writing memories.\n",
    "* [Ambient Agents Course](https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/memory.ipynb) provides a great overview of memory with a LangGraph agent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
